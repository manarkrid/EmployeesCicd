# Projet Employees Management - Documentation CI/CD de bout en bout

Ce dÃ©pÃ´t contient une solution de gestion des employÃ©s avec une automatisation CI/CD, un dÃ©ploiement Kubernetes et un monitoring avancÃ©.

---

## ğŸ—ï¸ 1. Architecture du Projet

L'architecture est basÃ©e sur une pile fullstack moderne et suit un modÃ¨le **3-Tier** conteneurisÃ© :
- **Frontend** : Angular (v18+) & Nginx
- **Backend** : Node.js (Express) & Sequelize
- **Base de donnÃ©es** : MySQL
- **Orchestration** : Kubernetes (Minikube)
- **CI/CD** : Jenkins & GitHub Actions

### SchÃ©ma Conceptuel

L'application suit une architecture **3-Tier** conteneurisÃ©e et orchestrÃ©e.

### Visualisation Graphique
![Architecture du Projet](./assets/preview.png)

---


##  2. Dockerisation de l'Application
Chaque composant possÃ¨de son propre `Dockerfile` optimisÃ© :

- **Backend** : Construit une image Node.js lÃ©gÃ¨re, installe les dÃ©pendances et expose le port `8080`.
- **Frontend** : Utilise une construction multi-Ã©tapes (Multistage build) :
  1. Build de l'application Angular via Node.js.
  2. Service des fichiers statiques via Nginx sur le port `80`.

**VÃ©rification locale** :
`docker-compose up --build` permet de valider que les conteneurs sont pleinement fonctionnels.

---

## âš™ï¸ 3. Pipeline Jenkins (CI/CD)
Le fichier `Jenkinsfile` Ã  la racine orchestre la chaÃ®ne de livraison :

1.  **Checkout** : RÃ©cupÃ¨re le code source depuis GitHub.
2.  **Build Docker Images** : Construit les images avec un tag basÃ© sur le numÃ©ro de build `${BUILD_NUMBER}`.
3.  **Push to Docker Hub** : Publie les images sur le dÃ©pÃ´t `manar2/employeemanagment_*`.
4.  **DÃ©ploiement GitOps** : 
    - Met Ã  jour les manifests Kubernetes avec les nouveaux tags d'images (`sed`).
    - Applique les changements sur le cluster via un conteneur `kubectl`.

---

## ğŸš€ 4. GitHub Actions (Alternative CD)
Un workflow GitHub Actions est disponible dans `.github/workflows/cd.yml`.

### Configuration requise :
1. **Secrets GitHub** : Ajoutez `DOCKER_HUB_TOKEN` dans votre dÃ©pÃ´t.
2. **Self-hosted Runner** : Indispensable pour l'accÃ¨s local Ã  Minikube.

---

## â˜¸ï¸ 5. Kubernetes (K8s)
Le dÃ©ploiement est gÃ©rÃ© via les manifests dans `/k8s` :

- **Deployments** : GÃ¨rent les rÃ©pliques pour `frontend`, `backend` et `mysql`.
- **Services** : 
  - `frontend` : ExposÃ© via un **LoadBalancer** (ou NodePort sur Minikube).
  - `backend` : Service interne accessible uniquement par le frontend.
  - `db` : Service interne pour MySQL.
- **Outil utilisÃ©** : `kubectl apply -f k8s/`.

---

## ğŸ“Š 6. Monitoring (Prometheus + Grafana)
Le monitoring est mis en place via la stack **kube-prometheus-stack** (Helm).

### A. Installation par ligne de commande (CMD)
```bash
# Ajouter le repo Helm
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Installer la stack
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
```

### B. AccÃ¨s via Navigateur (GUI)
1. **Port-forward** : `kubectl port-forward -n monitoring svc/monitoring-grafana 3000:80`
2. **Ouverture** : AccÃ©dez Ã  [http://localhost:3000](http://localhost:3000).
3. **Login** : `admin` / `prom-operator`.

### C. Exigences rÃ©alisÃ©es
- **Collecte** : Prometheus collecte automatiquement les mÃ©triques des nodes et pods du cluster.
- **Dashboards** : Importez des dashboards standards (ex: ID `1860` pour Node Exporter) pour visualiser l'Ã©tat du cluster.
- **MÃ©triques applicatives** : Surveillance de la latence HTTP et du taux d'erreur via les mÃ©triques exposÃ©es.
- **Alerting** : ğŸ”” Alerte Prometheus / Grafana â€“ Pods Running

=> Une rÃ¨gle dâ€™alerte a Ã©tÃ© mise en place dans Grafana afin de surveiller lâ€™Ã©tat des pods Kubernetes.

ğŸ“Œ RÃ¨gle configurÃ©e:
count(kube_pod_status_phase{phase="Running"}) < 20

ğŸ¯ Objectif:

Cette alerte surveille le nombre total de pods en Ã©tat Running dans le cluster Kubernetes.

Elle se dÃ©clenche lorsque le nombre de pods en cours dâ€™exÃ©cution devient infÃ©rieur Ã  20.

âš™ï¸ Fonctionnement:

Grafana interroge Prometheus Ã  intervalle rÃ©gulier (ex: chaque minute).

La mÃ©trique kube_pod_status_phase{phase="Running"} compte les pods actifs.

Si le nombre de pods Running passe sous le seuil dÃ©fini (20), lâ€™alerte est dÃ©clenchÃ©e.

Une notification email est envoyÃ©e aux utilisateurs configurÃ©s.

ğŸš¨ Cas dâ€™usage:

Cette alerte permet de dÃ©tecter :

* La chute dâ€™un ou plusieurs pods.

* Un problÃ¨me de dÃ©ploiement.

* Un crash dâ€™application.

* Un problÃ¨me de ressources (CPU / mÃ©moire).

Elle garantit une surveillance proactive du cluster et amÃ©liore la disponibilitÃ© des services.

---




